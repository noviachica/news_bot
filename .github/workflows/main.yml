name: News Crawler

on:
  schedule:
    - cron: '30 23 * * *'  # UTC 23:30 (한국 시간 08:30)
  workflow_dispatch:  # 수동 실행 가능

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install gspread oauth2client pandas requests beautifulsoup4
    
    - name: Run crawler
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIAL }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "환경 변수 확인:"
        echo "GOOGLE_CREDENTIALS 길이: ${#GOOGLE_CREDENTIALS}"
        echo "GOOGLE_CREDENTIALS 시작 부분: ${GOOGLE_CREDENTIALS:0:100}"
        echo "GITHUB_TOKEN 길이: ${#GITHUB_TOKEN}"
        echo "GITHUB_TOKEN 시작 부분: ${GITHUB_TOKEN:0:10}..."
        python crawler.py 
